{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Class to perform Self-Organizing Map Oversampling.\n",
    "Paper: https://doi.org/10.1016/j.eswa.2017.03.073\n",
    "\"\"\"\n",
    "\n",
    "from imblearn.over_sampling.base import BaseOverSampler\n",
    "import somoclu as somo\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from random import *\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "from math import isnan\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "class SOMO(BaseOverSampler):\n",
    "    \"\"\" \n",
    "    Self Organizing Map Oversampling Algorithm \n",
    "    An oversampling algorithm that leverages the dimensionality reducing and topological clustering \n",
    "    characteristics of Self-Organizing Maps. \n",
    "    Parameters\n",
    "    ----------\n",
    "    ratio : str, dict, or callable, optional (default='auto')\n",
    "        Ratio to use for resampling the data set.\n",
    "        - If ``str``, has to be one of: (i) ``'minority'``: resample the\n",
    "          minority class; (ii) ``'majority'``: resample the majority class,\n",
    "          (iii) ``'not minority'``: resample all classes apart of the minority\n",
    "          class, (iv) ``'all'``: resample all classes, and (v) ``'auto'``:\n",
    "          correspond to ``'all'`` with for over-sampling methods and ``'not\n",
    "          minority'`` for under-sampling methods. The classes targeted will be\n",
    "          over-sampled or under-sampled to achieve an equal number of sample\n",
    "          with the majority or minority class.\n",
    "        - If ``dict``, the keys correspond to the targeted classes. The values\n",
    "          correspond to the desired number of samples.\n",
    "        - If callable, function taking ``y`` and returns a ``dict``. The keys\n",
    "          correspond to the targeted classes. The values correspond to the\n",
    "          desired number of samples.\n",
    "    som_rows : number of rows for two-dimensional output map of SOM\n",
    "    som_cols : number of columns for two-dimensional output map of SOM\n",
    "    iterations : number of iterations to train the Self Organizing Map\n",
    "    filtered_cluster_ratio : Defined the treshold to identify a cluster as filtered cluster\n",
    "    inter_intra_cluster_ratio : Describes the ratio of inter- and intracluster generated samples,\n",
    "    a higher value indicates more intracluster created samples.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 ratio='auto',\n",
    "                 som_rows=10,\n",
    "                 som_cols=10,\n",
    "                 iterations=1000,\n",
    "                 filtered_cluster_ratio=0.5,\n",
    "                 inter_intra_cluster_ratio=0.5):\n",
    "        super(SOMO, self).__init__(ratio=ratio)\n",
    "        self.som_rows = som_rows\n",
    "        self.som_cols = som_cols\n",
    "        self.iterations = iterations\n",
    "        self.filtered_cluster_ratio = filtered_cluster_ratio\n",
    "        self.inter_intra_cluster_ratio = inter_intra_cluster_ratio\n",
    "\n",
    "    def _cluster(self, X_sub):\n",
    "        \"\"\"\n",
    "        Description: Clusters the normalized input data\n",
    "        Returns: som - Object with topological cluster map \n",
    "        \"\"\"\n",
    "        som = somo.Somoclu(self.som_cols, self.som_rows, compactsupport=False)\n",
    "        som.train(np.float32(X_sub), epochs=self.iterations)\n",
    "\n",
    "        return som\n",
    "\n",
    "    def _filter_Cluster(self, som, X_sub, y_sub, class_sample):\n",
    "        \"\"\"\n",
    "        Description: Identifies all filtered cluster and the number of minority samples belonging to them \n",
    "        Returns: som_cluster - Array of assigned clusters for each data sample, \n",
    "                 filtered_cluster_size - array of filtered cluster and number of samples in each\n",
    "        \"\"\"\n",
    "        som_cluster = pd.DataFrame(\n",
    "            [int(''.join(map(str, num))) for num in som.bmus])\n",
    "        som_cluster['Target'] = y_sub\n",
    "        cluster_ratio = som_cluster.groupby([0]).mean()\n",
    "        if self.majority_class > class_sample:\n",
    "            filtered_set_idx = cluster_ratio.loc[cluster_ratio['Target'] < (\n",
    "                (self.majority_class + class_sample) / 2)].index.values\n",
    "            minority_cluster_size = som_cluster[\n",
    "                som_cluster['Target'] < self.majority_class].groupby([0]).agg(\n",
    "                    ['count'])\n",
    "        else:\n",
    "            filtered_set_idx = cluster_ratio.loc[cluster_ratio['Target'] > (\n",
    "                (self.majority_class + class_sample) / 2)].index.values\n",
    "            minority_cluster_size = som_cluster[\n",
    "                som_cluster['Target'] > self.majority_class].groupby([0]).agg(\n",
    "                    ['count'])\n",
    "\n",
    "        filtered_cluster_size = minority_cluster_size.loc[np.array(\n",
    "            filtered_set_idx)]\n",
    "        filtered_cluster_size = filtered_cluster_size[\n",
    "            filtered_cluster_size > 1].dropna()\n",
    "\n",
    "        return som_cluster, filtered_cluster_size\n",
    "\n",
    "    def _calc_Distances(self, X_sub, class_sample, som_cluster,\n",
    "                        filtered_cluster_size):\n",
    "        \"\"\"\n",
    "        Description: Calculates average euclidean distances in each filtered cluster for each sample towards\n",
    "        all other samples and averages them\n",
    "        Returns: eucl_distances - array of average euclidean distance for each filtered cluster\n",
    "        \"\"\"\n",
    "        eucl_distances = []\n",
    "        for num in filtered_cluster_size.index:\n",
    "            input_idx = som_cluster[\n",
    "                (som_cluster[0] == num)\n",
    "                & (som_cluster['Target'] == class_sample)].index\n",
    "            individual_Distance = []\n",
    "            for idx in input_idx:\n",
    "                individual_Distance.append(\n",
    "                    np.mean([(np.linalg.norm(X_sub[idx] - X_sub[num]))\n",
    "                             for num in input_idx if num != idx]))\n",
    "            eucl_distances.append(np.mean(individual_Distance))\n",
    "\n",
    "        return eucl_distances\n",
    "\n",
    "    def _calc_Density(self, filtered_cluster_size, eucl_distances):\n",
    "        \"\"\"\n",
    "        Description: Calculates the density for each filtered cluster and neighbor relation\n",
    "        Returns: filtered_cluster_size - DataFrame with density for each filtered cluster\n",
    "                 neighbors - 2d array with all filtered cluster relations and their density\n",
    "        \"\"\"\n",
    "        # Calculate density in filtered cluster\n",
    "        filtered_cluster_size['Density'] = np.divide(\n",
    "            np.array(filtered_cluster_size, dtype=int).ravel(),\n",
    "            np.square(eucl_distances))\n",
    "\n",
    "        # Identify neighbors and calc Density\n",
    "        neighbors = []\n",
    "        fil_cl = pd.DataFrame(filtered_cluster_size.index.values).apply(\n",
    "            pd.Series)\n",
    "        for idx in fil_cl[0]:\n",
    "            cur_neighbors = fil_cl[\n",
    "                ((fil_cl <= idx + 1) & (fil_cl >= idx - 1))\n",
    "                | ((fil_cl >= idx - 11) & (fil_cl <= idx - 9))\n",
    "                | ((fil_cl <= idx + 11) & (fil_cl >= idx + 9))]\n",
    "            for i in cur_neighbors[0]:\n",
    "                if ((idx != i) & (isnan(i) != True)):\n",
    "                    neighbors.append([idx, int(i)])\n",
    "        for index, clust in pd.DataFrame(neighbors).iterrows():\n",
    "            neighbors[index].append(\n",
    "                (filtered_cluster_size.loc[clust[0]].Density +\n",
    "                 filtered_cluster_size.loc[clust[1]].Density))\n",
    "\n",
    "        return filtered_cluster_size, neighbors\n",
    "\n",
    "    def _oversample_intra(self, intra_Samples, X_sub, y_sub, class_sample,\n",
    "                          som_cluster, filtered_cluster_size):\n",
    "        \"\"\"\n",
    "        Description: Oversamples minority class in each filtered cluster\n",
    "        Returns: modified_X - oversampled X values\n",
    "                 modified_y - y values of minority class\n",
    "        \"\"\"\n",
    "        modified_X = np.empty((0, len(X_sub[0])), int)\n",
    "        modified_y = []\n",
    "        # Calculate Weights\n",
    "        weights = [(1 / den) / sum((1 / filtered_cluster_size.Density))\n",
    "                   for den in filtered_cluster_size.Density]\n",
    "\n",
    "        # Calculate amount of samples for each filtered cluster\n",
    "        samples = [int(weight * intra_Samples) for weight in weights]\n",
    "        while (intra_Samples - sum(samples) != 0):\n",
    "            random_index = randrange(0, len(samples))\n",
    "            samples[random_index] = samples[random_index] + 1\n",
    "\n",
    "        # Oversample amount of samples\n",
    "        for index, num in pd.DataFrame(filtered_cluster_size.index).iterrows():\n",
    "            if samples[index] == 0:\n",
    "                pass\n",
    "            else:\n",
    "                input_idx = som_cluster[(som_cluster[0] == num[0])].index\n",
    "                cur_X, cur_y = X_sub[input_idx], y_sub[input_idx]\n",
    "                if cur_y.mean() == class_sample:\n",
    "\n",
    "                    rand_maj = choice(\n",
    "                        np.where(y_sub == self.majority_class)[0])\n",
    "                    cur_X, cur_y = np.append(\n",
    "                        cur_X, [X_sub[rand_maj]], axis=0), np.append(\n",
    "                            cur_y, y_sub[rand_maj])\n",
    "\n",
    "                if len(cur_y[cur_y == class_sample]) <= 5:\n",
    "                    k_neighbors = 1\n",
    "                else:\n",
    "                    k_neighbors = 5\n",
    "                sm = SMOTE(\n",
    "                    ratio={class_sample: (samples[index] + len(cur_X) - 1)},\n",
    "                    k_neighbors=k_neighbors)\n",
    "                over_X, over_y = sm.fit_sample(\n",
    "                    np.array(cur_X), np.array(cur_y))\n",
    "                over_X, over_y = over_X[-samples[index]:], over_y[\n",
    "                    -samples[index]:]\n",
    "                modified_X, modified_y = np.append(\n",
    "                    modified_X, over_X, axis=0), np.append(modified_y, over_y)\n",
    "\n",
    "        return modified_X, modified_y\n",
    "\n",
    "    def _oversample_inter(self, inter_Samples, X_sub, y_sub, class_sample,\n",
    "                          som_cluster, neighbors):\n",
    "        \"\"\"\n",
    "        Description: Oversamples between filtered clusters that are topological neighbors\n",
    "        Returns: modified_X - oversampled X values\n",
    "                 modified_y - y values of minority class\n",
    "        \"\"\"\n",
    "\n",
    "        modified_X = np.empty((0, len(X_sub[0])), int)\n",
    "        modified_y = []\n",
    "\n",
    "        #Calculate Weights\n",
    "        neigh = pd.DataFrame(neighbors)\n",
    "        weights = [(1 / den) / sum((1 / neigh[2])) for den in neigh[2]]\n",
    "\n",
    "        #Calculate Samples\n",
    "        samples = [int(weight * inter_Samples) for weight in weights]\n",
    "        # Check that all intra_Samples are spread\n",
    "        while (inter_Samples - sum(samples) != 0):\n",
    "            random_index = randrange(0, len(samples))\n",
    "            samples[random_index] = samples[random_index] + 1\n",
    "\n",
    "        # Oversample amount of samples\n",
    "        for index, neigh in pd.DataFrame(neighbors).iterrows():\n",
    "            for i in range(0, samples[index]):\n",
    "                random_sample_A = choice(som_cluster[\n",
    "                    (som_cluster[0] == neigh[0])\n",
    "                    & (som_cluster['Target'] == class_sample)].index)\n",
    "                random_sample_B = choice(som_cluster[\n",
    "                    (som_cluster[0] == neigh[1])\n",
    "                    & (som_cluster['Target'] == class_sample)].index)\n",
    "                random_maj = choice(som_cluster[(\n",
    "                    som_cluster['Target'] == self.majority_class)].index)\n",
    "                cur_X, cur_y = X_sub[[\n",
    "                    random_sample_A, random_sample_B, random_maj\n",
    "                ]], y_sub[[random_sample_A, random_sample_B, random_maj]]\n",
    "                sm = SMOTE(ratio={class_sample: 3}, k_neighbors=1)\n",
    "                over_X, over_y = sm.fit_sample(\n",
    "                    np.array(cur_X), np.array(cur_y))\n",
    "                modified_X, modified_y = np.append(\n",
    "                    modified_X, over_X[len(cur_X):], axis=0), np.append(\n",
    "                        modified_y, over_y[len(cur_X):])\n",
    "        return modified_X, modified_y\n",
    "\n",
    "    def _sample(self, X, y):\n",
    "        \"\"\"\n",
    "        Description: Oversampling of each minority class  \n",
    "        Returns: X - Original data input with oversampled data samples \n",
    "                 y - original input with oversampled target classes\n",
    "        \"\"\"\n",
    "\n",
    "        X = normalize(X)\n",
    "        self.majority_class = max(Counter(y), key=Counter(y).get)\n",
    "        samples_X, samples_y = np.empty((0, len(X[0])), int), []\n",
    "\n",
    "        for class_sample, num_samples in self.ratio_.items():\n",
    "\n",
    "            if class_sample == self.majority_class:\n",
    "                pass\n",
    "            else:\n",
    "\n",
    "                X_sub = X[[np.flatnonzero((y == class_sample)\n",
    "                         | (y == self.majority_class))][0]]\n",
    "                y_sub = y[[np.flatnonzero((y == class_sample)\n",
    "                         | (y == self.majority_class))][0]]\n",
    "\n",
    "                som = self._cluster(X_sub)\n",
    "                som_cluster, filtered_cluster_size = self._filter_Cluster(\n",
    "                    som, X_sub, y_sub, class_sample)\n",
    "\n",
    "                eucl_distances = self._calc_Distances(\n",
    "                    X_sub, class_sample, som_cluster, filtered_cluster_size)\n",
    "                filtered_cluster_size, neighbors = self._calc_Density(\n",
    "                    filtered_cluster_size, eucl_distances)\n",
    "                intra_X, intra_y = self._oversample_intra(\n",
    "                    int(num_samples * self.inter_intra_cluster_ratio), X_sub,\n",
    "                    y_sub, class_sample, som_cluster, filtered_cluster_size)\n",
    "                inter_X, inter_y = self._oversample_inter(\n",
    "                    int(num_samples * (1 - self.inter_intra_cluster_ratio)),\n",
    "                    X_sub, y_sub, class_sample, som_cluster, neighbors)\n",
    "\n",
    "                samples_X = np.append(\n",
    "                    samples_X, np.append(intra_X, inter_X, axis=0), axis=0)\n",
    "                samples_y = np.append(samples_y, np.append(intra_y, inter_y))\n",
    "\n",
    "        X = np.append(X, samples_X, axis=0)\n",
    "        y = np.append(y, samples_y)\n",
    "\n",
    "        return (X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments & ToDo's:\n",
    "1. What happends when there are no filtered cluster? TODO: Currently throws error\n",
    "2. What happens when there are no neighbors? \n",
    "3. Should there be a better function to calculate weights? If the density value is really small, nearly all samples will be places in that filtered cluster\n",
    "4. Denormalize Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
